{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LSTM for international airline passengers problem with window regression framing\n",
    "import numpy\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "# dataframe = read_csv('w_d_v.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "dataframe = read_csv('00.txt', usecols=[0], engine='python',skiprows=-1)\n",
    "all_data = read_csv('all_data.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "allData=all_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 3\n",
    "trainX, trainY = create_dataset(dataset, look_back)\n",
    "AllX, AllY = create_dataset(allData, look_back)\n",
    "trainY=numpy.reshape(trainY,(trainY.shape[0],-1))\n",
    "AllY=numpy.reshape(AllY,(AllY.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encX = OneHotEncoder()\n",
    "encX.fit(AllX)\n",
    "encY = OneHotEncoder()\n",
    "encY.fit(AllY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_one=encX.transform(trainX).toarray()\n",
    "train_X=numpy.reshape(trainX_one,(trainX_one.shape[0],look_back,-1))\n",
    "train_Y=encY.transform(trainY).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test, b_train, b_test = train_test_split(train_X, train_Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2]),name=\"lstm\"))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(300))  # return a single vector of dimension 32\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(a_train.shape[2],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "plot_model(model, to_file='lstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_pattern (InputLayer)      (None, 3, 200)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_51 (Sequential)      (None, 300)          2435824     input_pattern[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_id (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 301)          0           sequential_51[12][0]             \n",
      "                                                                 input_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "C (Dense)                       (None, 250)          75500       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 250)          0           C[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 200)          50200       dropout_67[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,561,524\n",
      "Trainable params: 2,561,524\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense,Merge\n",
    "from keras.models import Model\n",
    "\n",
    "# x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "# lstm_out = LSTM(512,input_shape=(3, a_train.shape[2]))(main_input)\n",
    "input_pattern = Input(shape=(3, a_train.shape[2]),name=\"input_pattern\")\n",
    "input_id = Input(shape=(1,),name=\"input_id\")\n",
    "\n",
    "# T1 = Sequential()\n",
    "# # model.add(Embedding(max_features, output_dim=256))\n",
    "# T1.add(LSTM(512,return_sequences=True,input_shape=(3, a_train.shape[2]),name=\"A\"))  # returns a sequence of vectors of dimension 32\n",
    "# T1.add(LSTM(300,name=\"B\"))  # return a single vector of dimension 32\n",
    "# T1.add(Dropout(0.2))\n",
    "\n",
    "lstm_out = LSTM(512,return_sequences=True,input_shape=(3, a_train.shape[2]))(input_pattern)\n",
    "lstm_out = LSTM(300)(lstm_out)\n",
    "lstm_out = Dropout(0.2)(lstm_out)\n",
    "\n",
    "x = keras.layers.concatenate([T1(input_pattern), input_id])\n",
    "# T.add(Merge([T1,input_id],mode='concat',concat_axis=-1,name='PP'))\n",
    "x=Dense(250,activation='relu',name=\"C\")(x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Dense(a_train.shape[2],activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[input_pattern,input_id], outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary()) # Summarize Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='t_lstm.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 226 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 5.0659 - acc: 0.2655 - val_loss: 3.7479 - val_acc: 0.3846\n",
      "Epoch 2/100\n",
      " - 1s - loss: 3.0673 - acc: 0.3142 - val_loss: 2.9154 - val_acc: 0.1923\n",
      "Epoch 3/100\n",
      " - 2s - loss: 2.7753 - acc: 0.2611 - val_loss: 3.1905 - val_acc: 0.3846\n",
      "Epoch 4/100\n",
      " - 2s - loss: 2.6226 - acc: 0.2920 - val_loss: 2.8403 - val_acc: 0.3846\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.4734 - acc: 0.3319 - val_loss: 2.9044 - val_acc: 0.3846\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.4727 - acc: 0.3053 - val_loss: 2.8349 - val_acc: 0.3846\n",
      "Epoch 7/100\n",
      " - 2s - loss: 2.4494 - acc: 0.3230 - val_loss: 2.9059 - val_acc: 0.3846\n",
      "Epoch 8/100\n",
      " - 2s - loss: 2.4299 - acc: 0.3363 - val_loss: 2.8921 - val_acc: 0.3846\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.4259 - acc: 0.3496 - val_loss: 3.0215 - val_acc: 0.3846\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2.4308 - acc: 0.3274 - val_loss: 3.0480 - val_acc: 0.3846\n",
      "Epoch 11/100\n",
      " - 1s - loss: 2.4012 - acc: 0.3407 - val_loss: 3.0349 - val_acc: 0.3846\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.3776 - acc: 0.2920 - val_loss: 2.9156 - val_acc: 0.4231\n",
      "Epoch 13/100\n",
      " - 2s - loss: 2.3798 - acc: 0.3407 - val_loss: 2.9935 - val_acc: 0.4231\n",
      "Epoch 14/100\n",
      " - 2s - loss: 2.3026 - acc: 0.3274 - val_loss: 3.1429 - val_acc: 0.4231\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.2806 - acc: 0.3363 - val_loss: 3.0444 - val_acc: 0.4231\n",
      "Epoch 16/100\n",
      " - 2s - loss: 2.2357 - acc: 0.3628 - val_loss: 3.3098 - val_acc: 0.4231\n",
      "Epoch 17/100\n",
      " - 2s - loss: 2.2159 - acc: 0.3673 - val_loss: 3.1632 - val_acc: 0.3846\n",
      "Epoch 18/100\n",
      " - 2s - loss: 2.1375 - acc: 0.3805 - val_loss: 3.1338 - val_acc: 0.3846\n",
      "Epoch 19/100\n",
      " - 2s - loss: 2.0306 - acc: 0.3761 - val_loss: 3.2715 - val_acc: 0.4615\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.9813 - acc: 0.3407 - val_loss: 3.3940 - val_acc: 0.4615\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f8ed1f848b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m           \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m           \u001b[0mfeed_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0municode\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(a_train, b_train, epochs=100, batch_size=16, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "# main_input = Sequential()\n",
    "# main_input.add(LSTM(512,return_sequences=True,input_shape=(3, a_train.shape[2]))) \n",
    "\n",
    "pattern_output = Dense(1, activation='sigmoid', name='pattern_output')(lstm_out)\n",
    "\n",
    "UserId_input = Input(shape=(a_train.shape[0],), name='UserId_input')\n",
    "x = keras.layers.concatenate([UserId_input, pattern_output])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(a_train.shape[2], activation='softmax', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, UserId_input], outputs=[main_output, pattern_output])\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy', 'pattern_output': 'categorical_crossentropy'},\n",
    "              metrics=['accuracy'])\n",
    "plot_model(model, to_file='New_lstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.zeros(a_train.shape[0])\n",
    "k=k.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n  ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-2361cd5141ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                 \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1651\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                 \u001b[0mval_ins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n  ..."
     ]
    }
   ],
   "source": [
    "model.fit([a_train,k], [b_train,b_train], epochs=100, batch_size=16, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 226 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.4579 - acc: 0.3363 - val_loss: 2.8475 - val_acc: 0.3846\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.4008 - acc: 0.3451 - val_loss: 2.8954 - val_acc: 0.3846\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.3854 - acc: 0.3274 - val_loss: 2.8316 - val_acc: 0.3846\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.4072 - acc: 0.3186 - val_loss: 2.8694 - val_acc: 0.3846\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.3989 - acc: 0.3451 - val_loss: 2.9294 - val_acc: 0.3846\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.4000 - acc: 0.2699 - val_loss: 2.8634 - val_acc: 0.4231\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.3390 - acc: 0.3363 - val_loss: 3.0185 - val_acc: 0.3846\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.3124 - acc: 0.3407 - val_loss: 3.0019 - val_acc: 0.3462\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.3052 - acc: 0.3319 - val_loss: 3.0947 - val_acc: 0.4231\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2.2796 - acc: 0.3407 - val_loss: 3.0116 - val_acc: 0.3462\n",
      "Epoch 11/100\n",
      " - 1s - loss: 2.2473 - acc: 0.3363 - val_loss: 3.0202 - val_acc: 0.3462\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.1905 - acc: 0.3363 - val_loss: 3.2322 - val_acc: 0.3462\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.1072 - acc: 0.3584 - val_loss: 2.9773 - val_acc: 0.3846\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.0494 - acc: 0.3496 - val_loss: 3.3331 - val_acc: 0.4231\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.0509 - acc: 0.3894 - val_loss: 3.3274 - val_acc: 0.4231\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.9773 - acc: 0.4071 - val_loss: 3.1107 - val_acc: 0.3846\n",
      "Epoch 17/100\n",
      " - 1s - loss: 1.8994 - acc: 0.4027 - val_loss: 3.1345 - val_acc: 0.3462\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.7649 - acc: 0.4159 - val_loss: 3.3115 - val_acc: 0.3846\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.7216 - acc: 0.4159 - val_loss: 3.5761 - val_acc: 0.3846\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.6483 - acc: 0.4425 - val_loss: 3.3133 - val_acc: 0.3462\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.6391 - acc: 0.4336 - val_loss: 3.5833 - val_acc: 0.3846\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.5916 - acc: 0.4513 - val_loss: 3.6448 - val_acc: 0.3846\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.6006 - acc: 0.4646 - val_loss: 3.5134 - val_acc: 0.3846\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.4956 - acc: 0.4779 - val_loss: 3.6380 - val_acc: 0.3846\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.4142 - acc: 0.5265 - val_loss: 3.5353 - val_acc: 0.3462\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.4241 - acc: 0.5177 - val_loss: 3.8111 - val_acc: 0.3462\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.3916 - acc: 0.5354 - val_loss: 3.9742 - val_acc: 0.3846\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.3826 - acc: 0.5398 - val_loss: 3.6787 - val_acc: 0.3846\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.2617 - acc: 0.5354 - val_loss: 3.8603 - val_acc: 0.3077\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.3619 - acc: 0.5310 - val_loss: 3.6538 - val_acc: 0.3462\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.2483 - acc: 0.5752 - val_loss: 3.7672 - val_acc: 0.3077\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.2453 - acc: 0.5575 - val_loss: 4.0419 - val_acc: 0.2692\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.2247 - acc: 0.5398 - val_loss: 3.8391 - val_acc: 0.3077\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.2307 - acc: 0.5619 - val_loss: 3.5131 - val_acc: 0.3077\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.2280 - acc: 0.5752 - val_loss: 4.0361 - val_acc: 0.3077\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.2513 - acc: 0.5221 - val_loss: 4.2090 - val_acc: 0.3077\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.1364 - acc: 0.6106 - val_loss: 4.1205 - val_acc: 0.3077\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.0578 - acc: 0.6372 - val_loss: 4.1778 - val_acc: 0.2692\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.1430 - acc: 0.5664 - val_loss: 4.4219 - val_acc: 0.3077\n",
      "Epoch 40/100\n",
      " - 1s - loss: 1.0878 - acc: 0.6106 - val_loss: 4.1480 - val_acc: 0.3462\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.0313 - acc: 0.6593 - val_loss: 4.3597 - val_acc: 0.2308\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.0535 - acc: 0.5929 - val_loss: 4.3307 - val_acc: 0.4231\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.0084 - acc: 0.6239 - val_loss: 4.1421 - val_acc: 0.2692\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.9309 - acc: 0.6283 - val_loss: 4.3574 - val_acc: 0.3077\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.8897 - acc: 0.6681 - val_loss: 4.4519 - val_acc: 0.2692\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.9107 - acc: 0.6549 - val_loss: 4.3955 - val_acc: 0.3077\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.9536 - acc: 0.6239 - val_loss: 4.2698 - val_acc: 0.3077\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.9636 - acc: 0.6283 - val_loss: 4.2195 - val_acc: 0.2308\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.0021 - acc: 0.6593 - val_loss: 4.1786 - val_acc: 0.3462\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.9973 - acc: 0.6504 - val_loss: 4.4738 - val_acc: 0.2308\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.0400 - acc: 0.6681 - val_loss: 4.3856 - val_acc: 0.3462\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.0583 - acc: 0.6372 - val_loss: 4.0107 - val_acc: 0.3462\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.9954 - acc: 0.6372 - val_loss: 4.2339 - val_acc: 0.3462\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.9583 - acc: 0.6327 - val_loss: 4.5003 - val_acc: 0.2692\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.8704 - acc: 0.6637 - val_loss: 4.3015 - val_acc: 0.2308\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.8037 - acc: 0.7301 - val_loss: 4.1405 - val_acc: 0.3462\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.8797 - acc: 0.6504 - val_loss: 4.5570 - val_acc: 0.2692\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.8503 - acc: 0.6593 - val_loss: 4.6643 - val_acc: 0.3077\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.8059 - acc: 0.7080 - val_loss: 4.5335 - val_acc: 0.2308\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.8386 - acc: 0.6947 - val_loss: 4.4081 - val_acc: 0.1923\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.7961 - acc: 0.6814 - val_loss: 4.5832 - val_acc: 0.3077\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.6982 - acc: 0.7522 - val_loss: 4.5704 - val_acc: 0.2692\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.7337 - acc: 0.7168 - val_loss: 4.7214 - val_acc: 0.3077\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.7224 - acc: 0.7035 - val_loss: 4.6089 - val_acc: 0.2308\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.7090 - acc: 0.7168 - val_loss: 4.7131 - val_acc: 0.2308\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.7014 - acc: 0.7212 - val_loss: 4.8719 - val_acc: 0.2692\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.7572 - acc: 0.7080 - val_loss: 4.9364 - val_acc: 0.1923\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.7225 - acc: 0.7257 - val_loss: 4.5290 - val_acc: 0.2692\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.7036 - acc: 0.7478 - val_loss: 4.6161 - val_acc: 0.2308\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.6922 - acc: 0.7301 - val_loss: 4.6658 - val_acc: 0.2692\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.6865 - acc: 0.7389 - val_loss: 4.6717 - val_acc: 0.2692\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.6628 - acc: 0.7655 - val_loss: 4.7870 - val_acc: 0.2692\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.6970 - acc: 0.7522 - val_loss: 4.8209 - val_acc: 0.2692\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.6849 - acc: 0.7389 - val_loss: 4.9868 - val_acc: 0.2308\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.6615 - acc: 0.7434 - val_loss: 4.8797 - val_acc: 0.2308\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.6737 - acc: 0.7611 - val_loss: 5.0378 - val_acc: 0.2308\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.6551 - acc: 0.7611 - val_loss: 4.8319 - val_acc: 0.1154\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.5908 - acc: 0.7655 - val_loss: 4.9686 - val_acc: 0.2692\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.6414 - acc: 0.7522 - val_loss: 4.9212 - val_acc: 0.1538\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.6862 - acc: 0.7080 - val_loss: 4.4656 - val_acc: 0.3077\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.6354 - acc: 0.7566 - val_loss: 4.4451 - val_acc: 0.2692\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.6476 - acc: 0.7345 - val_loss: 4.6722 - val_acc: 0.2692\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.6615 - acc: 0.7611 - val_loss: 5.1449 - val_acc: 0.3077\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.7876 - acc: 0.7655 - val_loss: 4.7377 - val_acc: 0.1923\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.6904 - acc: 0.7611 - val_loss: 4.3656 - val_acc: 0.1923\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.7136 - acc: 0.7212 - val_loss: 4.2030 - val_acc: 0.2308\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.7115 - acc: 0.7301 - val_loss: 4.5376 - val_acc: 0.2692\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.6508 - acc: 0.7434 - val_loss: 4.6372 - val_acc: 0.2692\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.6708 - acc: 0.7566 - val_loss: 4.8032 - val_acc: 0.1923\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.7001 - acc: 0.7478 - val_loss: 4.8429 - val_acc: 0.2692\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.6520 - acc: 0.7566 - val_loss: 5.0850 - val_acc: 0.1538\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.6585 - acc: 0.7699 - val_loss: 5.1038 - val_acc: 0.2308\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.6137 - acc: 0.7566 - val_loss: 5.0507 - val_acc: 0.2692\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.5955 - acc: 0.7522 - val_loss: 5.1115 - val_acc: 0.2692\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.6559 - acc: 0.7478 - val_loss: 4.9753 - val_acc: 0.2308\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.6416 - acc: 0.7566 - val_loss: 4.8292 - val_acc: 0.2692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 1s - loss: 0.5909 - acc: 0.7655 - val_loss: 4.9425 - val_acc: 0.1923\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.6218 - acc: 0.7788 - val_loss: 5.0224 - val_acc: 0.1923\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.6314 - acc: 0.7566 - val_loss: 5.0488 - val_acc: 0.2308\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.5999 - acc: 0.7434 - val_loss: 5.0392 - val_acc: 0.1923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51251ff9e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=16, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_X, train_Y, batch_size=64, verbose=2, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(train_X)\n",
    "D=np.argmax(train_Y,axis = 1)\n",
    "E=np.argmax(trainPredict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=0 #total number of right\n",
    "for i,t in enumerate(E):\n",
    "    if D[i]==t :\n",
    "        A=A+1\n",
    "print(A/D.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
