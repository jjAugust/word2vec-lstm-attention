{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LSTM for international airline passengers problem with window regression framing\n",
    "import numpy\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "# dataframe = read_csv('w_d_v.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "dataframe = read_csv('00.txt', usecols=[0], engine='python',skiprows=-1)\n",
    "all_data = read_csv('all_data.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "allData=all_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 3\n",
    "trainX, trainY = create_dataset(dataset, look_back)\n",
    "AllX, AllY = create_dataset(allData, look_back)\n",
    "trainY=numpy.reshape(trainY,(trainY.shape[0],-1))\n",
    "AllY=numpy.reshape(AllY,(AllY.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.n_values_ is: [200 200 200]\n",
      "enc.feature_indices_ is: [  0 200 400 600]\n"
     ]
    }
   ],
   "source": [
    "encX = OneHotEncoder()\n",
    "encX.fit(AllX)\n",
    "encY = OneHotEncoder()\n",
    "encY.fit(AllY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_one=encX.transform(trainX).toarray()\n",
    "train_X=numpy.reshape(trainX_one,(trainX_one.shape[0],look_back,-1))\n",
    "train_Y=encY.transform(trainY).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test, b_train, b_test = train_test_split(train_X, train_Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2])name=\"\"))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(300))  # return a single vector of dimension 32\n",
    "#model.add(Dense(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(a_train.shape[2],activation='softmax'))\n",
    "#\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='lstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=8, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_X, train_Y, batch_size=64, verbose=2, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=np.argmax(train_Y,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "E=np.argmax(trainPredict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=0\n",
    "for i,t in enumerate(E):\n",
    "    if D[i]==t :\n",
    "        A=A+1\n",
    "        \n",
    "print(A)\n",
    "print(D.shape)\n",
    "print(187/252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "\n",
    "model.add(LSTM(256))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "\n",
    "# model.compile(loss='mean_squared_logarithmic_error', optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.compile(loss='categorical_hinge', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='logcosh', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='cosine_proximity', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=64, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "\n",
    "model.add(LSTM(256))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "\n",
    "# model.compile(loss='mean_squared_logarithmic_error', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_hinge', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='logcosh', optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.compile(loss='cosine_proximity', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=256, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "\n",
    "model.add(LSTM(256))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_hinge', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='logcosh', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='cosine_proximity', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=64, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install h5py \n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True), input_shape=(3, a_train.shape[2])))\n",
    "# model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "\n",
    "model.add(LSTM(256))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "model.compile(loss='cosine_proximity', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=64, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('wdv.h5')   # HDF5 file, you have to pip3 install h5py if don't have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('wdv.h5')#调整好，保存为每个用户的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = read_csv('weekend_day_test.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "Tdataset = testdata.values\n",
    "look_back = 3\n",
    "TX, TY = create_dataset(Tdataset, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encX = OneHotEncoder()\n",
    "encX.fit(AllX)\n",
    "TX=encX.transform(TX).toarray()\n",
    "TestX=numpy.reshape(TX,(TX.shape[0],look_back,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY=numpy.reshape(TY,(TY.shape[0],-1))\n",
    "\n",
    "encY = OneHotEncoder()\n",
    "encY.fit(AllY)\n",
    "TestY=encY.transform(TY).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(TestX, TestY, batch_size=64, verbose=2, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(a_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainPredict[0])\n",
    "print(b_train[0]*trainPredict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
