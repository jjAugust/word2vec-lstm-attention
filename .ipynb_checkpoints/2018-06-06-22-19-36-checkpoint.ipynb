{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LSTM for international airline passengers problem with window regression framing\n",
    "import numpy\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "# dataframe = read_csv('w_d_v.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "dataframe = read_csv('00.txt', usecols=[0], engine='python',skiprows=-1)\n",
    "\n",
    "all_data = read_csv('all_data.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "allData=all_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[157],\n",
       "       [150],\n",
       "       [150],\n",
       "       [ 31],\n",
       "       [ 31],\n",
       "       [ 31],\n",
       "       [130],\n",
       "       [ 65],\n",
       "       [  1],\n",
       "       [ 26],\n",
       "       [  1],\n",
       "       [131],\n",
       "       [  1],\n",
       "       [ 26],\n",
       "       [108],\n",
       "       [ 52],\n",
       "       [131],\n",
       "       [ 26],\n",
       "       [ 26],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [126],\n",
       "       [ 64],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [108],\n",
       "       [181],\n",
       "       [150],\n",
       "       [157],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [167],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [157],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [196],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [139],\n",
       "       [ 68],\n",
       "       [150],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       [108],\n",
       "       [ 15],\n",
       "       [ 92],\n",
       "       [150],\n",
       "       [116],\n",
       "       [196],\n",
       "       [108],\n",
       "       [193],\n",
       "       [ 65],\n",
       "       [ 90],\n",
       "       [ 64],\n",
       "       [159],\n",
       "       [159],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [197],\n",
       "       [159],\n",
       "       [ 28],\n",
       "       [159],\n",
       "       [108],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [108],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [  1],\n",
       "       [108],\n",
       "       [ 97],\n",
       "       [131],\n",
       "       [108],\n",
       "       [159],\n",
       "       [ 28],\n",
       "       [ 28],\n",
       "       [146],\n",
       "       [108],\n",
       "       [  1],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [162],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [196],\n",
       "       [ 34],\n",
       "       [ 52],\n",
       "       [ 70],\n",
       "       [150],\n",
       "       [ 84],\n",
       "       [ 51],\n",
       "       [196],\n",
       "       [ 79],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [116],\n",
       "       [ 32],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [  1],\n",
       "       [197],\n",
       "       [197],\n",
       "       [ 52],\n",
       "       [119],\n",
       "       [198],\n",
       "       [181],\n",
       "       [181],\n",
       "       [ 52],\n",
       "       [104],\n",
       "       [  1],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  7],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [108],\n",
       "       [ 57],\n",
       "       [ 57],\n",
       "       [191],\n",
       "       [ 15],\n",
       "       [162],\n",
       "       [132],\n",
       "       [132],\n",
       "       [ 56],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [198],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [157],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [116],\n",
       "       [116],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [184],\n",
       "       [108],\n",
       "       [157],\n",
       "       [157],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [131],\n",
       "       [ 17]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 3\n",
    "trainX, trainY = create_dataset(dataset, look_back)\n",
    "AllX, AllY = create_dataset(allData, look_back)\n",
    "trainY=numpy.reshape(trainY,(trainY.shape[0],-1))\n",
    "AllY=numpy.reshape(AllY,(AllY.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 31],\n",
       "       [ 31],\n",
       "       [ 31],\n",
       "       [130],\n",
       "       [ 65],\n",
       "       [  1],\n",
       "       [ 26],\n",
       "       [  1],\n",
       "       [131],\n",
       "       [  1],\n",
       "       [ 26],\n",
       "       [108],\n",
       "       [ 52],\n",
       "       [131],\n",
       "       [ 26],\n",
       "       [ 26],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [126],\n",
       "       [ 64],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [108],\n",
       "       [181],\n",
       "       [150],\n",
       "       [157],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [167],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [157],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [196],\n",
       "       [150],\n",
       "       [150],\n",
       "       [150],\n",
       "       [139],\n",
       "       [ 68],\n",
       "       [150],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       [108],\n",
       "       [ 15],\n",
       "       [ 92],\n",
       "       [150],\n",
       "       [116],\n",
       "       [196],\n",
       "       [108],\n",
       "       [193],\n",
       "       [ 65],\n",
       "       [ 90],\n",
       "       [ 64],\n",
       "       [159],\n",
       "       [159],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [197],\n",
       "       [159],\n",
       "       [ 28],\n",
       "       [159],\n",
       "       [108],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [108],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [  1],\n",
       "       [108],\n",
       "       [ 97],\n",
       "       [131],\n",
       "       [108],\n",
       "       [159],\n",
       "       [ 28],\n",
       "       [ 28],\n",
       "       [146],\n",
       "       [108],\n",
       "       [  1],\n",
       "       [150],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [162],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [196],\n",
       "       [ 34],\n",
       "       [ 52],\n",
       "       [ 70],\n",
       "       [150],\n",
       "       [ 84],\n",
       "       [ 51],\n",
       "       [196],\n",
       "       [ 79],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [116],\n",
       "       [ 32],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [  1],\n",
       "       [197],\n",
       "       [197],\n",
       "       [ 52],\n",
       "       [119],\n",
       "       [198],\n",
       "       [181],\n",
       "       [181],\n",
       "       [ 52],\n",
       "       [104],\n",
       "       [  1],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  7],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [108],\n",
       "       [ 57],\n",
       "       [ 57],\n",
       "       [191],\n",
       "       [ 15],\n",
       "       [162],\n",
       "       [132],\n",
       "       [132],\n",
       "       [ 56],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [198],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [157],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [116],\n",
       "       [116],\n",
       "       [150],\n",
       "       [150],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [181],\n",
       "       [184],\n",
       "       [108],\n",
       "       [157],\n",
       "       [157],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [181],\n",
       "       [  1],\n",
       "       [181],\n",
       "       [131]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.n_values_ is: [200 200 200]\n",
      "enc.feature_indices_ is: [  0 200 400 600]\n"
     ]
    }
   ],
   "source": [
    "encX = OneHotEncoder()\n",
    "encX.fit(AllX)\n",
    "print (\"enc.n_values_ is:\",encX.n_values_)\n",
    "print (\"enc.feature_indices_ is:\",encX.feature_indices_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.n_values_ is: [200]\n",
      "enc.feature_indices_ is: [  0 200]\n"
     ]
    }
   ],
   "source": [
    "encY = OneHotEncoder()\n",
    "encY.fit(AllY)\n",
    "print (\"enc.n_values_ is:\",encY.n_values_)\n",
    "print (\"enc.feature_indices_ is:\",encY.feature_indices_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_one=encX.transform(trainX).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=numpy.reshape(trainX_one,(trainX_one.shape[0],look_back,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y=encY.transform(trainY).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test, b_train, b_test = train_test_split(train_X, train_Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "\n",
    "model.add(LSTM(256))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "\n",
    "# model.compile(loss='mean_squared_logarithmic_error', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_hinge', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='logcosh', optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.compile(loss='cosine_proximity', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=256, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(200))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "#\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=56, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "\n",
    "model.add(LSTM(256))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "\n",
    "# model.compile(loss='mean_squared_logarithmic_error', optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.compile(loss='categorical_hinge', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='logcosh', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='cosine_proximity', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=64, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "\n",
    "model.add(LSTM(256))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_hinge', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='logcosh', optimizer='rmsprop',metrics=['accuracy'])\n",
    "# model.compile(loss='cosine_proximity', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=64, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install h5py \n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1773 samples, validate on 197 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: -1.6753e-01 - acc: 0.1359 - val_loss: -1.9868e-01 - val_acc: 0.1269\n",
      "Epoch 2/100\n",
      " - 4s - loss: -2.7132e-01 - acc: 0.2245 - val_loss: -2.1690e-01 - val_acc: 0.1675\n",
      "Epoch 3/100\n",
      " - 4s - loss: -3.0682e-01 - acc: 0.2578 - val_loss: -2.1477e-01 - val_acc: 0.1472\n",
      "Epoch 4/100\n",
      " - 4s - loss: -3.2844e-01 - acc: 0.2803 - val_loss: -2.1599e-01 - val_acc: 0.1726\n",
      "Epoch 5/100\n",
      " - 4s - loss: -3.4212e-01 - acc: 0.2961 - val_loss: -2.1895e-01 - val_acc: 0.1827\n",
      "Epoch 6/100\n",
      " - 4s - loss: -3.5470e-01 - acc: 0.3125 - val_loss: -2.2254e-01 - val_acc: 0.1624\n",
      "Epoch 7/100\n",
      " - 4s - loss: -3.6380e-01 - acc: 0.3192 - val_loss: -2.1836e-01 - val_acc: 0.1827\n",
      "Epoch 8/100\n",
      " - 4s - loss: -3.7142e-01 - acc: 0.3305 - val_loss: -2.1550e-01 - val_acc: 0.1675\n",
      "Epoch 9/100\n",
      " - 4s - loss: -3.7821e-01 - acc: 0.3305 - val_loss: -2.1419e-01 - val_acc: 0.1624\n",
      "Epoch 10/100\n",
      " - 4s - loss: -3.8583e-01 - acc: 0.3412 - val_loss: -2.1536e-01 - val_acc: 0.1726\n",
      "Epoch 11/100\n",
      " - 4s - loss: -3.9052e-01 - acc: 0.3531 - val_loss: -2.1333e-01 - val_acc: 0.1726\n",
      "Epoch 12/100\n",
      " - 4s - loss: -3.9532e-01 - acc: 0.3548 - val_loss: -2.1220e-01 - val_acc: 0.1574\n",
      "Epoch 13/100\n",
      " - 4s - loss: -4.0170e-01 - acc: 0.3666 - val_loss: -2.2124e-01 - val_acc: 0.1878\n",
      "Epoch 14/100\n",
      " - 4s - loss: -4.0525e-01 - acc: 0.3677 - val_loss: -2.2538e-01 - val_acc: 0.1929\n",
      "Epoch 15/100\n",
      " - 4s - loss: -4.1133e-01 - acc: 0.3677 - val_loss: -2.1812e-01 - val_acc: 0.1878\n",
      "Epoch 16/100\n",
      " - 4s - loss: -4.1545e-01 - acc: 0.3824 - val_loss: -2.2138e-01 - val_acc: 0.1878\n",
      "Epoch 17/100\n",
      " - 4s - loss: -4.2057e-01 - acc: 0.3830 - val_loss: -2.1450e-01 - val_acc: 0.1777\n",
      "Epoch 18/100\n",
      " - 4s - loss: -4.2527e-01 - acc: 0.3959 - val_loss: -2.1516e-01 - val_acc: 0.1878\n",
      "Epoch 19/100\n",
      " - 4s - loss: -4.3067e-01 - acc: 0.3926 - val_loss: -2.1287e-01 - val_acc: 0.1726\n",
      "Epoch 20/100\n",
      " - 4s - loss: -4.3575e-01 - acc: 0.4112 - val_loss: -2.1023e-01 - val_acc: 0.1827\n",
      "Epoch 21/100\n",
      " - 4s - loss: -4.4115e-01 - acc: 0.4140 - val_loss: -2.1326e-01 - val_acc: 0.1675\n",
      "Epoch 22/100\n",
      " - 4s - loss: -4.4650e-01 - acc: 0.4157 - val_loss: -2.1229e-01 - val_acc: 0.1878\n",
      "Epoch 23/100\n",
      " - 4s - loss: -4.5314e-01 - acc: 0.4332 - val_loss: -2.1262e-01 - val_acc: 0.1827\n",
      "Epoch 24/100\n",
      " - 4s - loss: -4.5966e-01 - acc: 0.4349 - val_loss: -2.0460e-01 - val_acc: 0.1827\n",
      "Epoch 25/100\n",
      " - 4s - loss: -4.6743e-01 - acc: 0.4540 - val_loss: -2.0904e-01 - val_acc: 0.1878\n",
      "Epoch 26/100\n",
      " - 4s - loss: -4.7577e-01 - acc: 0.4642 - val_loss: -2.0686e-01 - val_acc: 0.1929\n",
      "Epoch 27/100\n",
      " - 4s - loss: -4.8428e-01 - acc: 0.4772 - val_loss: -2.0931e-01 - val_acc: 0.1929\n",
      "Epoch 28/100\n",
      " - 4s - loss: -4.9267e-01 - acc: 0.4890 - val_loss: -2.0049e-01 - val_acc: 0.1827\n",
      "Epoch 29/100\n",
      " - 4s - loss: -5.0271e-01 - acc: 0.5155 - val_loss: -1.9929e-01 - val_acc: 0.1827\n",
      "Epoch 30/100\n",
      " - 4s - loss: -5.1318e-01 - acc: 0.5296 - val_loss: -2.0267e-01 - val_acc: 0.1980\n",
      "Epoch 31/100\n",
      " - 4s - loss: -5.2299e-01 - acc: 0.5477 - val_loss: -2.0653e-01 - val_acc: 0.1878\n",
      "Epoch 32/100\n",
      " - 4s - loss: -5.3353e-01 - acc: 0.5680 - val_loss: -1.9946e-01 - val_acc: 0.1878\n",
      "Epoch 33/100\n",
      " - 4s - loss: -5.4448e-01 - acc: 0.5939 - val_loss: -2.0136e-01 - val_acc: 0.1827\n",
      "Epoch 34/100\n",
      " - 4s - loss: -5.5588e-01 - acc: 0.6024 - val_loss: -2.0185e-01 - val_acc: 0.1980\n",
      "Epoch 35/100\n",
      " - 4s - loss: -5.6529e-01 - acc: 0.6261 - val_loss: -1.9261e-01 - val_acc: 0.1980\n",
      "Epoch 36/100\n",
      " - 4s - loss: -5.7835e-01 - acc: 0.6520 - val_loss: -1.9106e-01 - val_acc: 0.1878\n",
      "Epoch 37/100\n",
      " - 4s - loss: -5.8793e-01 - acc: 0.6734 - val_loss: -1.9361e-01 - val_acc: 0.1777\n",
      "Epoch 38/100\n",
      " - 4s - loss: -5.9882e-01 - acc: 0.6757 - val_loss: -1.8165e-01 - val_acc: 0.1777\n",
      "Epoch 39/100\n",
      " - 4s - loss: -6.0956e-01 - acc: 0.7045 - val_loss: -1.8753e-01 - val_acc: 0.1675\n",
      "Epoch 40/100\n",
      " - 4s - loss: -6.2069e-01 - acc: 0.7152 - val_loss: -1.8632e-01 - val_acc: 0.1726\n",
      "Epoch 41/100\n",
      " - 4s - loss: -6.3066e-01 - acc: 0.7140 - val_loss: -1.9007e-01 - val_acc: 0.1929\n",
      "Epoch 42/100\n",
      " - 4s - loss: -6.4221e-01 - acc: 0.7372 - val_loss: -1.8485e-01 - val_acc: 0.1827\n",
      "Epoch 43/100\n",
      " - 4s - loss: -6.5175e-01 - acc: 0.7490 - val_loss: -1.8661e-01 - val_acc: 0.1726\n",
      "Epoch 44/100\n",
      " - 4s - loss: -6.6287e-01 - acc: 0.7654 - val_loss: -1.8137e-01 - val_acc: 0.1929\n",
      "Epoch 45/100\n",
      " - 4s - loss: -6.7236e-01 - acc: 0.7699 - val_loss: -1.7422e-01 - val_acc: 0.1777\n",
      "Epoch 46/100\n",
      " - 4s - loss: -6.8207e-01 - acc: 0.7817 - val_loss: -1.8012e-01 - val_acc: 0.1827\n",
      "Epoch 47/100\n",
      " - 4s - loss: -6.9144e-01 - acc: 0.7941 - val_loss: -1.7830e-01 - val_acc: 0.1929\n",
      "Epoch 48/100\n",
      " - 4s - loss: -7.0060e-01 - acc: 0.8009 - val_loss: -1.8045e-01 - val_acc: 0.1675\n",
      "Epoch 49/100\n",
      " - 4s - loss: -7.0916e-01 - acc: 0.8133 - val_loss: -1.7464e-01 - val_acc: 0.1726\n",
      "Epoch 50/100\n",
      " - 4s - loss: -7.1807e-01 - acc: 0.8195 - val_loss: -1.7269e-01 - val_acc: 0.1624\n",
      "Epoch 51/100\n",
      " - 4s - loss: -7.2574e-01 - acc: 0.8229 - val_loss: -1.7094e-01 - val_acc: 0.1980\n",
      "Epoch 52/100\n",
      " - 4s - loss: -7.3411e-01 - acc: 0.8319 - val_loss: -1.7428e-01 - val_acc: 0.1827\n",
      "Epoch 53/100\n",
      " - 4s - loss: -7.4234e-01 - acc: 0.8370 - val_loss: -1.7267e-01 - val_acc: 0.1777\n",
      "Epoch 54/100\n",
      " - 4s - loss: -7.5021e-01 - acc: 0.8421 - val_loss: -1.7202e-01 - val_acc: 0.1624\n",
      "Epoch 55/100\n",
      " - 4s - loss: -7.5780e-01 - acc: 0.8500 - val_loss: -1.7372e-01 - val_acc: 0.1827\n",
      "Epoch 56/100\n",
      " - 4s - loss: -7.6469e-01 - acc: 0.8528 - val_loss: -1.7614e-01 - val_acc: 0.1777\n",
      "Epoch 57/100\n",
      " - 4s - loss: -7.7251e-01 - acc: 0.8596 - val_loss: -1.7020e-01 - val_acc: 0.1726\n",
      "Epoch 58/100\n",
      " - 4s - loss: -7.7867e-01 - acc: 0.8641 - val_loss: -1.6461e-01 - val_acc: 0.1675\n",
      "Epoch 59/100\n",
      " - 4s - loss: -7.8546e-01 - acc: 0.8658 - val_loss: -1.7094e-01 - val_acc: 0.1726\n",
      "Epoch 60/100\n",
      " - 4s - loss: -7.9133e-01 - acc: 0.8697 - val_loss: -1.6717e-01 - val_acc: 0.1827\n",
      "Epoch 61/100\n",
      " - 4s - loss: -7.9810e-01 - acc: 0.8742 - val_loss: -1.6332e-01 - val_acc: 0.1726\n",
      "Epoch 62/100\n",
      " - 4s - loss: -8.0191e-01 - acc: 0.8737 - val_loss: -1.7156e-01 - val_acc: 0.1726\n",
      "Epoch 63/100\n",
      " - 4s - loss: -8.0870e-01 - acc: 0.8782 - val_loss: -1.5422e-01 - val_acc: 0.1675\n",
      "Epoch 64/100\n",
      " - 4s - loss: -8.1340e-01 - acc: 0.8827 - val_loss: -1.6002e-01 - val_acc: 0.1624\n",
      "Epoch 65/100\n",
      " - 4s - loss: -8.1867e-01 - acc: 0.8832 - val_loss: -1.6185e-01 - val_acc: 0.1777\n",
      "Epoch 66/100\n",
      " - 4s - loss: -8.2253e-01 - acc: 0.8861 - val_loss: -1.6846e-01 - val_acc: 0.1726\n",
      "Epoch 67/100\n",
      " - 4s - loss: -8.2805e-01 - acc: 0.8923 - val_loss: -1.6494e-01 - val_acc: 0.1827\n",
      "Epoch 68/100\n",
      " - 4s - loss: -8.3200e-01 - acc: 0.8866 - val_loss: -1.6050e-01 - val_acc: 0.1574\n",
      "Epoch 69/100\n",
      " - 4s - loss: -8.3548e-01 - acc: 0.8917 - val_loss: -1.5486e-01 - val_acc: 0.1675\n",
      "Epoch 70/100\n",
      " - 4s - loss: -8.3998e-01 - acc: 0.8979 - val_loss: -1.6043e-01 - val_acc: 0.1726\n",
      "Epoch 71/100\n",
      " - 4s - loss: -8.4323e-01 - acc: 0.8951 - val_loss: -1.5941e-01 - val_acc: 0.1574\n",
      "Epoch 72/100\n",
      " - 4s - loss: -8.4668e-01 - acc: 0.8951 - val_loss: -1.5541e-01 - val_acc: 0.1675\n",
      "Epoch 73/100\n",
      " - 4s - loss: -8.5044e-01 - acc: 0.8968 - val_loss: -1.5666e-01 - val_acc: 0.1726\n",
      "Epoch 74/100\n",
      " - 4s - loss: -8.5354e-01 - acc: 0.9024 - val_loss: -1.5377e-01 - val_acc: 0.1675\n",
      "Epoch 75/100\n",
      " - 4s - loss: -8.5523e-01 - acc: 0.8973 - val_loss: -1.4713e-01 - val_acc: 0.1472\n",
      "Epoch 76/100\n",
      " - 4s - loss: -8.5801e-01 - acc: 0.8973 - val_loss: -1.5726e-01 - val_acc: 0.1523\n",
      "Epoch 77/100\n",
      " - 4s - loss: -8.6074e-01 - acc: 0.8957 - val_loss: -1.6157e-01 - val_acc: 0.1726\n",
      "Epoch 78/100\n",
      " - 4s - loss: -8.6399e-01 - acc: 0.8990 - val_loss: -1.5160e-01 - val_acc: 0.1675\n",
      "Epoch 79/100\n",
      " - 4s - loss: -8.6441e-01 - acc: 0.8979 - val_loss: -1.4663e-01 - val_acc: 0.1675\n",
      "Epoch 80/100\n",
      " - 4s - loss: -8.6798e-01 - acc: 0.8996 - val_loss: -1.5840e-01 - val_acc: 0.1624\n",
      "Epoch 81/100\n",
      " - 4s - loss: -8.7050e-01 - acc: 0.9019 - val_loss: -1.5082e-01 - val_acc: 0.1574\n",
      "Epoch 82/100\n",
      " - 4s - loss: -8.7199e-01 - acc: 0.9030 - val_loss: -1.5287e-01 - val_acc: 0.1523\n",
      "Epoch 83/100\n",
      " - 4s - loss: -8.7407e-01 - acc: 0.8979 - val_loss: -1.5333e-01 - val_acc: 0.1624\n",
      "Epoch 84/100\n",
      " - 4s - loss: -8.7500e-01 - acc: 0.9002 - val_loss: -1.4927e-01 - val_acc: 0.1472\n",
      "Epoch 85/100\n",
      " - 4s - loss: -8.7665e-01 - acc: 0.9002 - val_loss: -1.5327e-01 - val_acc: 0.1371\n",
      "Epoch 86/100\n",
      " - 4s - loss: -8.7895e-01 - acc: 0.9013 - val_loss: -1.5359e-01 - val_acc: 0.1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 4s - loss: -8.8099e-01 - acc: 0.8973 - val_loss: -1.5712e-01 - val_acc: 0.1472\n",
      "Epoch 88/100\n",
      " - 4s - loss: -8.8177e-01 - acc: 0.9024 - val_loss: -1.5418e-01 - val_acc: 0.1472\n",
      "Epoch 89/100\n",
      " - 4s - loss: -8.8283e-01 - acc: 0.9030 - val_loss: -1.6430e-01 - val_acc: 0.1675\n",
      "Epoch 90/100\n",
      " - 4s - loss: -8.8433e-01 - acc: 0.8996 - val_loss: -1.5513e-01 - val_acc: 0.1827\n",
      "Epoch 91/100\n",
      " - 4s - loss: -8.8543e-01 - acc: 0.8996 - val_loss: -1.5499e-01 - val_acc: 0.1574\n",
      "Epoch 92/100\n",
      " - 4s - loss: -8.8691e-01 - acc: 0.9047 - val_loss: -1.5055e-01 - val_acc: 0.1523\n",
      "Epoch 93/100\n",
      " - 4s - loss: -8.8771e-01 - acc: 0.9013 - val_loss: -1.5408e-01 - val_acc: 0.1574\n",
      "Epoch 94/100\n",
      " - 4s - loss: -8.8912e-01 - acc: 0.8985 - val_loss: -1.5372e-01 - val_acc: 0.1472\n",
      "Epoch 95/100\n",
      " - 4s - loss: -8.9022e-01 - acc: 0.9007 - val_loss: -1.5114e-01 - val_acc: 0.1574\n",
      "Epoch 96/100\n",
      " - 4s - loss: -8.9113e-01 - acc: 0.9002 - val_loss: -1.5974e-01 - val_acc: 0.1523\n",
      "Epoch 97/100\n",
      " - 4s - loss: -8.9276e-01 - acc: 0.9075 - val_loss: -1.5020e-01 - val_acc: 0.1523\n",
      "Epoch 98/100\n",
      " - 4s - loss: -8.9317e-01 - acc: 0.9030 - val_loss: -1.5673e-01 - val_acc: 0.1624\n",
      "Epoch 99/100\n",
      " - 4s - loss: -8.9380e-01 - acc: 0.9041 - val_loss: -1.5869e-01 - val_acc: 0.1574\n",
      "Epoch 100/100\n",
      " - 4s - loss: -8.9609e-01 - acc: 0.9041 - val_loss: -1.5913e-01 - val_acc: 0.1624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff338a8ac50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True), input_shape=(3, a_train.shape[2])))\n",
    "# model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "\n",
    "model.add(LSTM(256))  # return a single vector of dimension 32\n",
    "model.add(Dense(a_train.shape[2]))\n",
    "model.compile(loss='cosine_proximity', optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=64, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('wdv.h5')   # HDF5 file, you have to pip3 install h5py if don't have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xiongjunjie/Documents/code_doc/python\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('wdv.h5')#调整好，保存为每个用户的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = read_csv('weekend_day_test.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "Tdataset = testdata.values\n",
    "look_back = 3\n",
    "TX, TY = create_dataset(Tdataset, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "encX = OneHotEncoder()\n",
    "encX.fit(AllX)\n",
    "TX=encX.transform(TX).toarray()\n",
    "TestX=numpy.reshape(TX,(TX.shape[0],look_back,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY=numpy.reshape(TY,(TY.shape[0],-1))\n",
    "\n",
    "encY = OneHotEncoder()\n",
    "encY.fit(AllY)\n",
    "TestY=encY.transform(TY).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.07590291933040273, 0.07372175980975029]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(TestX, TestY, batch_size=64, verbose=2, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(a_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainPredict[0])\n",
    "print(b_train[0]*trainPredict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
