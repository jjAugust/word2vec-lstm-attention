{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LSTM for international airline passengers problem with window regression framing\n",
    "import numpy\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "# dataframe = read_csv('w_d_v.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "dataframe = read_csv('00.txt', usecols=[0], engine='python',skiprows=-1)\n",
    "all_data = read_csv('all_data.csv', usecols=[7], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "allData=all_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 3\n",
    "trainX, trainY = create_dataset(dataset, look_back)\n",
    "AllX, AllY = create_dataset(allData, look_back)\n",
    "trainY=numpy.reshape(trainY,(trainY.shape[0],-1))\n",
    "AllY=numpy.reshape(AllY,(AllY.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encX = OneHotEncoder()\n",
    "encX.fit(AllX)\n",
    "encY = OneHotEncoder()\n",
    "encY.fit(AllY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_one=encX.transform(trainX).toarray()\n",
    "train_X=numpy.reshape(trainX_one,(trainX_one.shape[0],look_back,-1))\n",
    "train_Y=encY.transform(trainY).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test, b_train, b_test = train_test_split(train_X, train_Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(512,return_sequences=True,\n",
    "               input_shape=(3, a_train.shape[2]),name=\"lstm\"))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(300))  # return a single vector of dimension 32\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(a_train.shape[2],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "plot_model(model, to_file='lstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_pattern (InputLayer)   (None, 3, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 3, 512)            1460224   \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 300)               975600    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "C (Dense)                    (None, 250)               75250     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 200)               50200     \n",
      "=================================================================\n",
      "Total params: 2,561,274\n",
      "Trainable params: 2,561,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense,Merge\n",
    "from keras.models import Model\n",
    "\n",
    "input_pattern = Input(shape=(3, a_train.shape[2]),name=\"input_pattern\")\n",
    "\n",
    "lstm_out = LSTM(512,return_sequences=True,input_shape=(3, a_train.shape[2]))(input_pattern)\n",
    "lstm_out = LSTM(300)(lstm_out)\n",
    "lstm_out = Dropout(0.2)(lstm_out)\n",
    "\n",
    "# T.add(Merge([T1,input_id],mode='concat',concat_axis=-1,name='PP'))\n",
    "x=Dense(250,activation='relu',name=\"C\")(lstm_out)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Dense(a_train.shape[2],activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_pattern, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary()) # Summarize Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_pattern (InputLayer)      (None, 3, 200)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  (None, 3, 512)       1460224     input_pattern[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                  (None, 300)          975600      lstm_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 300)          0           lstm_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_id (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 301)          0           dropout_70[0][0]                 \n",
      "                                                                 input_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "C (Dense)                       (None, 250)          75500       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 250)          0           C[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 200)          50200       dropout_71[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,561,524\n",
      "Trainable params: 2,561,524\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense,Merge\n",
    "from keras.models import Model\n",
    "\n",
    "input_pattern = Input(shape=(3, a_train.shape[2]),name=\"input_pattern\")\n",
    "input_id = Input(shape=(1,),name=\"input_id\")\n",
    "\n",
    "lstm_out = LSTM(512,return_sequences=True,input_shape=(3, a_train.shape[2]))(input_pattern)\n",
    "lstm_out = LSTM(300)(lstm_out)\n",
    "lstm_out = Dropout(0.2)(lstm_out)\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, input_id])\n",
    "# T.add(Merge([T1,input_id],mode='concat',concat_axis=-1,name='PP'))\n",
    "x=Dense(250,activation='relu',name=\"C\")(x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Dense(a_train.shape[2],activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[input_pattern,input_id], outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary()) # Summarize Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='t_lstm.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 226 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      " - 29s - loss: 5.0395 - acc: 0.3009 - val_loss: 3.4506 - val_acc: 0.3846\n",
      "Epoch 2/100\n",
      " - 1s - loss: 3.0772 - acc: 0.3274 - val_loss: 2.8870 - val_acc: 0.1538\n",
      "Epoch 3/100\n",
      " - 2s - loss: 2.6809 - acc: 0.2743 - val_loss: 2.7782 - val_acc: 0.3846\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.5079 - acc: 0.3230 - val_loss: 2.8515 - val_acc: 0.3846\n",
      "Epoch 5/100\n",
      " - 2s - loss: 2.4787 - acc: 0.3319 - val_loss: 2.7720 - val_acc: 0.3846\n",
      "Epoch 6/100\n",
      " - 2s - loss: 2.4619 - acc: 0.3407 - val_loss: 2.8186 - val_acc: 0.3846\n",
      "Epoch 7/100\n",
      " - 2s - loss: 2.4939 - acc: 0.3274 - val_loss: 3.1057 - val_acc: 0.3846\n",
      "Epoch 8/100\n",
      " - 2s - loss: 2.4641 - acc: 0.3186 - val_loss: 2.9404 - val_acc: 0.4231\n",
      "Epoch 9/100\n",
      " - 2s - loss: 2.4015 - acc: 0.3274 - val_loss: 2.9346 - val_acc: 0.3846\n",
      "Epoch 10/100\n",
      " - 2s - loss: 2.3857 - acc: 0.3407 - val_loss: 3.1665 - val_acc: 0.3846\n",
      "Epoch 11/100\n",
      " - 2s - loss: 2.3875 - acc: 0.3540 - val_loss: 2.9602 - val_acc: 0.3846\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.4091 - acc: 0.2566 - val_loss: 3.0965 - val_acc: 0.3846\n",
      "Epoch 13/100\n",
      " - 2s - loss: 2.2801 - acc: 0.3451 - val_loss: 3.1679 - val_acc: 0.4615\n",
      "Epoch 14/100\n",
      " - 2s - loss: 2.2495 - acc: 0.3673 - val_loss: 3.1042 - val_acc: 0.4615\n",
      "Epoch 15/100\n",
      " - 2s - loss: 2.2341 - acc: 0.3451 - val_loss: 3.1271 - val_acc: 0.4615\n",
      "Epoch 16/100\n",
      " - 2s - loss: 2.1909 - acc: 0.3097 - val_loss: 3.0969 - val_acc: 0.4615\n",
      "Epoch 17/100\n",
      " - 2s - loss: 2.1152 - acc: 0.3938 - val_loss: 3.1749 - val_acc: 0.3462\n",
      "Epoch 18/100\n",
      " - 2s - loss: 2.0733 - acc: 0.3540 - val_loss: 3.4419 - val_acc: 0.3846\n",
      "Epoch 19/100\n",
      " - 2s - loss: 2.0124 - acc: 0.3230 - val_loss: 3.2927 - val_acc: 0.4231\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.9857 - acc: 0.4071 - val_loss: 3.3821 - val_acc: 0.4615\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.8796 - acc: 0.4159 - val_loss: 3.5616 - val_acc: 0.4231\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.8294 - acc: 0.4159 - val_loss: 3.3796 - val_acc: 0.3846\n",
      "Epoch 23/100\n",
      " - 2s - loss: 1.8254 - acc: 0.3982 - val_loss: 3.5885 - val_acc: 0.4231\n",
      "Epoch 24/100\n",
      " - 2s - loss: 1.7670 - acc: 0.4248 - val_loss: 3.6403 - val_acc: 0.3462\n",
      "Epoch 25/100\n",
      " - 2s - loss: 1.7403 - acc: 0.4513 - val_loss: 3.5060 - val_acc: 0.4231\n",
      "Epoch 26/100\n",
      " - 2s - loss: 1.6370 - acc: 0.5000 - val_loss: 3.7801 - val_acc: 0.4231\n",
      "Epoch 27/100\n",
      " - 2s - loss: 1.6052 - acc: 0.4115 - val_loss: 3.8443 - val_acc: 0.3462\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.6841 - acc: 0.4558 - val_loss: 3.4966 - val_acc: 0.3077\n",
      "Epoch 29/100\n",
      " - 2s - loss: 1.5461 - acc: 0.4779 - val_loss: 3.7180 - val_acc: 0.3846\n",
      "Epoch 30/100\n",
      " - 2s - loss: 1.4934 - acc: 0.5088 - val_loss: 3.7461 - val_acc: 0.2308\n",
      "Epoch 31/100\n",
      " - 2s - loss: 1.3921 - acc: 0.5088 - val_loss: 3.8823 - val_acc: 0.3462\n",
      "Epoch 32/100\n",
      " - 2s - loss: 1.3764 - acc: 0.5044 - val_loss: 3.9568 - val_acc: 0.3077\n",
      "Epoch 33/100\n",
      " - 2s - loss: 1.3304 - acc: 0.5487 - val_loss: 3.9423 - val_acc: 0.3077\n",
      "Epoch 34/100\n",
      " - 2s - loss: 1.3495 - acc: 0.5354 - val_loss: 3.7582 - val_acc: 0.1923\n",
      "Epoch 35/100\n",
      " - 2s - loss: 1.2630 - acc: 0.5442 - val_loss: 3.9419 - val_acc: 0.3462\n",
      "Epoch 36/100\n",
      " - 2s - loss: 1.2197 - acc: 0.5929 - val_loss: 3.9224 - val_acc: 0.3077\n",
      "Epoch 37/100\n",
      " - 2s - loss: 1.1589 - acc: 0.6106 - val_loss: 3.9689 - val_acc: 0.3462\n",
      "Epoch 38/100\n",
      " - 2s - loss: 1.1680 - acc: 0.5841 - val_loss: 3.9986 - val_acc: 0.3462\n",
      "Epoch 39/100\n",
      " - 2s - loss: 1.1928 - acc: 0.5885 - val_loss: 3.9512 - val_acc: 0.3077\n",
      "Epoch 40/100\n",
      " - 2s - loss: 1.0594 - acc: 0.6416 - val_loss: 4.1505 - val_acc: 0.3077\n",
      "Epoch 41/100\n",
      " - 2s - loss: 1.1003 - acc: 0.5796 - val_loss: 3.9067 - val_acc: 0.3077\n",
      "Epoch 42/100\n",
      " - 2s - loss: 1.0804 - acc: 0.5929 - val_loss: 3.9380 - val_acc: 0.2692\n",
      "Epoch 43/100\n",
      " - 2s - loss: 1.0303 - acc: 0.6327 - val_loss: 4.2228 - val_acc: 0.2692\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.9830 - acc: 0.6327 - val_loss: 4.2748 - val_acc: 0.3077\n",
      "Epoch 45/100\n",
      " - 3s - loss: 1.1287 - acc: 0.5487 - val_loss: 4.1398 - val_acc: 0.3077\n",
      "Epoch 46/100\n",
      " - 2s - loss: 1.0458 - acc: 0.6195 - val_loss: 3.8265 - val_acc: 0.2692\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.1090 - acc: 0.5885 - val_loss: 4.2386 - val_acc: 0.3462\n",
      "Epoch 48/100\n",
      " - 2s - loss: 0.9802 - acc: 0.6327 - val_loss: 4.0475 - val_acc: 0.3462\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.9957 - acc: 0.6416 - val_loss: 4.0059 - val_acc: 0.3077\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.9116 - acc: 0.6504 - val_loss: 4.2790 - val_acc: 0.3077\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.9705 - acc: 0.6460 - val_loss: 4.1096 - val_acc: 0.1923\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.9340 - acc: 0.6416 - val_loss: 4.3329 - val_acc: 0.3846\n",
      "Epoch 53/100\n",
      " - 2s - loss: 0.9623 - acc: 0.6504 - val_loss: 4.2292 - val_acc: 0.1923\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.8598 - acc: 0.6991 - val_loss: 4.2546 - val_acc: 0.3462\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.9048 - acc: 0.6858 - val_loss: 4.4720 - val_acc: 0.2308\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.8659 - acc: 0.6726 - val_loss: 4.5157 - val_acc: 0.1538\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.8630 - acc: 0.6814 - val_loss: 4.5944 - val_acc: 0.2692\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.8158 - acc: 0.7080 - val_loss: 4.2235 - val_acc: 0.3077\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.7934 - acc: 0.7035 - val_loss: 4.6024 - val_acc: 0.1923\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.8253 - acc: 0.7035 - val_loss: 4.6177 - val_acc: 0.2308\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.7826 - acc: 0.7080 - val_loss: 4.4086 - val_acc: 0.3462\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.7822 - acc: 0.7035 - val_loss: 4.3997 - val_acc: 0.2692\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.7690 - acc: 0.7301 - val_loss: 4.5546 - val_acc: 0.2692\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.7448 - acc: 0.7301 - val_loss: 4.4044 - val_acc: 0.3077\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.7123 - acc: 0.7389 - val_loss: 4.5416 - val_acc: 0.1923\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.6956 - acc: 0.7434 - val_loss: 4.7378 - val_acc: 0.3077\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.7651 - acc: 0.7124 - val_loss: 4.4383 - val_acc: 0.1923\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.7479 - acc: 0.7124 - val_loss: 4.6016 - val_acc: 0.2308\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.6919 - acc: 0.7389 - val_loss: 4.5635 - val_acc: 0.2692\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.6943 - acc: 0.7522 - val_loss: 4.7212 - val_acc: 0.2692\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.6770 - acc: 0.7611 - val_loss: 4.7397 - val_acc: 0.1923\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.7134 - acc: 0.7434 - val_loss: 4.8424 - val_acc: 0.2692\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.7635 - acc: 0.7168 - val_loss: 4.6233 - val_acc: 0.1538\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.7587 - acc: 0.7257 - val_loss: 4.5942 - val_acc: 0.1538\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.7171 - acc: 0.7080 - val_loss: 5.0492 - val_acc: 0.2308\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.7317 - acc: 0.7389 - val_loss: 4.2374 - val_acc: 0.3077\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.7391 - acc: 0.7257 - val_loss: 5.0224 - val_acc: 0.1923\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.8031 - acc: 0.7212 - val_loss: 5.0919 - val_acc: 0.2692\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.4525 - acc: 0.6150 - val_loss: 4.3055 - val_acc: 0.2308\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.1084 - acc: 0.6460 - val_loss: 4.6596 - val_acc: 0.2692\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.8675 - acc: 0.6726 - val_loss: 4.4609 - val_acc: 0.3077\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.7621 - acc: 0.7124 - val_loss: 4.5809 - val_acc: 0.2308\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.7603 - acc: 0.7124 - val_loss: 4.5528 - val_acc: 0.1923\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.7566 - acc: 0.7257 - val_loss: 4.4220 - val_acc: 0.2692\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.7284 - acc: 0.6903 - val_loss: 4.5558 - val_acc: 0.2308\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.7221 - acc: 0.7212 - val_loss: 4.7609 - val_acc: 0.2692\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.6695 - acc: 0.7389 - val_loss: 4.6008 - val_acc: 0.2692\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.6284 - acc: 0.7566 - val_loss: 4.8334 - val_acc: 0.2692\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.6661 - acc: 0.7212 - val_loss: 4.6498 - val_acc: 0.1538\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.6559 - acc: 0.7301 - val_loss: 4.9726 - val_acc: 0.2308\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.7740 - acc: 0.7566 - val_loss: 4.7157 - val_acc: 0.2308\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.7165 - acc: 0.7257 - val_loss: 4.9241 - val_acc: 0.2308\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.6523 - acc: 0.7743 - val_loss: 4.8079 - val_acc: 0.2308\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.6395 - acc: 0.7434 - val_loss: 4.9173 - val_acc: 0.1923\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.6440 - acc: 0.7345 - val_loss: 4.9694 - val_acc: 0.1923\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.6284 - acc: 0.7611 - val_loss: 5.0920 - val_acc: 0.1923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 1s - loss: 0.5776 - acc: 0.7920 - val_loss: 5.1261 - val_acc: 0.1923\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.6178 - acc: 0.7699 - val_loss: 4.9303 - val_acc: 0.1923\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.5993 - acc: 0.7611 - val_loss: 5.1117 - val_acc: 0.2308\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.5796 - acc: 0.7655 - val_loss: 5.1616 - val_acc: 0.1538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18114d828>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(a_train, b_train, epochs=100, batch_size=16, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "# main_input = Sequential()\n",
    "# main_input.add(LSTM(512,return_sequences=True,input_shape=(3, a_train.shape[2]))) \n",
    "\n",
    "pattern_output = Dense(1, activation='sigmoid', name='pattern_output')(lstm_out)\n",
    "\n",
    "UserId_input = Input(shape=(a_train.shape[0],), name='UserId_input')\n",
    "x = keras.layers.concatenate([UserId_input, pattern_output])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(a_train.shape[2], activation='softmax', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, UserId_input], outputs=[main_output, pattern_output])\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy', 'pattern_output': 'categorical_crossentropy'},\n",
    "              metrics=['accuracy'])\n",
    "plot_model(model, to_file='New_lstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.zeros(a_train.shape[0])\n",
    "k=k.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n  ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-2361cd5141ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                 \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1651\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                 \u001b[0mval_ins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n  ..."
     ]
    }
   ],
   "source": [
    "model.fit([a_train,k], [b_train,b_train], epochs=100, batch_size=16, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 226 samples, validate on 26 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.4579 - acc: 0.3363 - val_loss: 2.8475 - val_acc: 0.3846\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.4008 - acc: 0.3451 - val_loss: 2.8954 - val_acc: 0.3846\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.3854 - acc: 0.3274 - val_loss: 2.8316 - val_acc: 0.3846\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.4072 - acc: 0.3186 - val_loss: 2.8694 - val_acc: 0.3846\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.3989 - acc: 0.3451 - val_loss: 2.9294 - val_acc: 0.3846\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.4000 - acc: 0.2699 - val_loss: 2.8634 - val_acc: 0.4231\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.3390 - acc: 0.3363 - val_loss: 3.0185 - val_acc: 0.3846\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.3124 - acc: 0.3407 - val_loss: 3.0019 - val_acc: 0.3462\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.3052 - acc: 0.3319 - val_loss: 3.0947 - val_acc: 0.4231\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2.2796 - acc: 0.3407 - val_loss: 3.0116 - val_acc: 0.3462\n",
      "Epoch 11/100\n",
      " - 1s - loss: 2.2473 - acc: 0.3363 - val_loss: 3.0202 - val_acc: 0.3462\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.1905 - acc: 0.3363 - val_loss: 3.2322 - val_acc: 0.3462\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.1072 - acc: 0.3584 - val_loss: 2.9773 - val_acc: 0.3846\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.0494 - acc: 0.3496 - val_loss: 3.3331 - val_acc: 0.4231\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.0509 - acc: 0.3894 - val_loss: 3.3274 - val_acc: 0.4231\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.9773 - acc: 0.4071 - val_loss: 3.1107 - val_acc: 0.3846\n",
      "Epoch 17/100\n",
      " - 1s - loss: 1.8994 - acc: 0.4027 - val_loss: 3.1345 - val_acc: 0.3462\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.7649 - acc: 0.4159 - val_loss: 3.3115 - val_acc: 0.3846\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.7216 - acc: 0.4159 - val_loss: 3.5761 - val_acc: 0.3846\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.6483 - acc: 0.4425 - val_loss: 3.3133 - val_acc: 0.3462\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.6391 - acc: 0.4336 - val_loss: 3.5833 - val_acc: 0.3846\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.5916 - acc: 0.4513 - val_loss: 3.6448 - val_acc: 0.3846\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.6006 - acc: 0.4646 - val_loss: 3.5134 - val_acc: 0.3846\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.4956 - acc: 0.4779 - val_loss: 3.6380 - val_acc: 0.3846\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.4142 - acc: 0.5265 - val_loss: 3.5353 - val_acc: 0.3462\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.4241 - acc: 0.5177 - val_loss: 3.8111 - val_acc: 0.3462\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.3916 - acc: 0.5354 - val_loss: 3.9742 - val_acc: 0.3846\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.3826 - acc: 0.5398 - val_loss: 3.6787 - val_acc: 0.3846\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.2617 - acc: 0.5354 - val_loss: 3.8603 - val_acc: 0.3077\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.3619 - acc: 0.5310 - val_loss: 3.6538 - val_acc: 0.3462\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.2483 - acc: 0.5752 - val_loss: 3.7672 - val_acc: 0.3077\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.2453 - acc: 0.5575 - val_loss: 4.0419 - val_acc: 0.2692\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.2247 - acc: 0.5398 - val_loss: 3.8391 - val_acc: 0.3077\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.2307 - acc: 0.5619 - val_loss: 3.5131 - val_acc: 0.3077\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.2280 - acc: 0.5752 - val_loss: 4.0361 - val_acc: 0.3077\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.2513 - acc: 0.5221 - val_loss: 4.2090 - val_acc: 0.3077\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.1364 - acc: 0.6106 - val_loss: 4.1205 - val_acc: 0.3077\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.0578 - acc: 0.6372 - val_loss: 4.1778 - val_acc: 0.2692\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.1430 - acc: 0.5664 - val_loss: 4.4219 - val_acc: 0.3077\n",
      "Epoch 40/100\n",
      " - 1s - loss: 1.0878 - acc: 0.6106 - val_loss: 4.1480 - val_acc: 0.3462\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.0313 - acc: 0.6593 - val_loss: 4.3597 - val_acc: 0.2308\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.0535 - acc: 0.5929 - val_loss: 4.3307 - val_acc: 0.4231\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.0084 - acc: 0.6239 - val_loss: 4.1421 - val_acc: 0.2692\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.9309 - acc: 0.6283 - val_loss: 4.3574 - val_acc: 0.3077\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.8897 - acc: 0.6681 - val_loss: 4.4519 - val_acc: 0.2692\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.9107 - acc: 0.6549 - val_loss: 4.3955 - val_acc: 0.3077\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.9536 - acc: 0.6239 - val_loss: 4.2698 - val_acc: 0.3077\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.9636 - acc: 0.6283 - val_loss: 4.2195 - val_acc: 0.2308\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.0021 - acc: 0.6593 - val_loss: 4.1786 - val_acc: 0.3462\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.9973 - acc: 0.6504 - val_loss: 4.4738 - val_acc: 0.2308\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.0400 - acc: 0.6681 - val_loss: 4.3856 - val_acc: 0.3462\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.0583 - acc: 0.6372 - val_loss: 4.0107 - val_acc: 0.3462\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.9954 - acc: 0.6372 - val_loss: 4.2339 - val_acc: 0.3462\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.9583 - acc: 0.6327 - val_loss: 4.5003 - val_acc: 0.2692\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.8704 - acc: 0.6637 - val_loss: 4.3015 - val_acc: 0.2308\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.8037 - acc: 0.7301 - val_loss: 4.1405 - val_acc: 0.3462\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.8797 - acc: 0.6504 - val_loss: 4.5570 - val_acc: 0.2692\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.8503 - acc: 0.6593 - val_loss: 4.6643 - val_acc: 0.3077\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.8059 - acc: 0.7080 - val_loss: 4.5335 - val_acc: 0.2308\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.8386 - acc: 0.6947 - val_loss: 4.4081 - val_acc: 0.1923\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.7961 - acc: 0.6814 - val_loss: 4.5832 - val_acc: 0.3077\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.6982 - acc: 0.7522 - val_loss: 4.5704 - val_acc: 0.2692\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.7337 - acc: 0.7168 - val_loss: 4.7214 - val_acc: 0.3077\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.7224 - acc: 0.7035 - val_loss: 4.6089 - val_acc: 0.2308\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.7090 - acc: 0.7168 - val_loss: 4.7131 - val_acc: 0.2308\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.7014 - acc: 0.7212 - val_loss: 4.8719 - val_acc: 0.2692\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.7572 - acc: 0.7080 - val_loss: 4.9364 - val_acc: 0.1923\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.7225 - acc: 0.7257 - val_loss: 4.5290 - val_acc: 0.2692\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.7036 - acc: 0.7478 - val_loss: 4.6161 - val_acc: 0.2308\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.6922 - acc: 0.7301 - val_loss: 4.6658 - val_acc: 0.2692\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.6865 - acc: 0.7389 - val_loss: 4.6717 - val_acc: 0.2692\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.6628 - acc: 0.7655 - val_loss: 4.7870 - val_acc: 0.2692\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.6970 - acc: 0.7522 - val_loss: 4.8209 - val_acc: 0.2692\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.6849 - acc: 0.7389 - val_loss: 4.9868 - val_acc: 0.2308\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.6615 - acc: 0.7434 - val_loss: 4.8797 - val_acc: 0.2308\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.6737 - acc: 0.7611 - val_loss: 5.0378 - val_acc: 0.2308\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.6551 - acc: 0.7611 - val_loss: 4.8319 - val_acc: 0.1154\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.5908 - acc: 0.7655 - val_loss: 4.9686 - val_acc: 0.2692\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.6414 - acc: 0.7522 - val_loss: 4.9212 - val_acc: 0.1538\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.6862 - acc: 0.7080 - val_loss: 4.4656 - val_acc: 0.3077\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.6354 - acc: 0.7566 - val_loss: 4.4451 - val_acc: 0.2692\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.6476 - acc: 0.7345 - val_loss: 4.6722 - val_acc: 0.2692\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.6615 - acc: 0.7611 - val_loss: 5.1449 - val_acc: 0.3077\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.7876 - acc: 0.7655 - val_loss: 4.7377 - val_acc: 0.1923\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.6904 - acc: 0.7611 - val_loss: 4.3656 - val_acc: 0.1923\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.7136 - acc: 0.7212 - val_loss: 4.2030 - val_acc: 0.2308\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.7115 - acc: 0.7301 - val_loss: 4.5376 - val_acc: 0.2692\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.6508 - acc: 0.7434 - val_loss: 4.6372 - val_acc: 0.2692\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.6708 - acc: 0.7566 - val_loss: 4.8032 - val_acc: 0.1923\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.7001 - acc: 0.7478 - val_loss: 4.8429 - val_acc: 0.2692\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.6520 - acc: 0.7566 - val_loss: 5.0850 - val_acc: 0.1538\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.6585 - acc: 0.7699 - val_loss: 5.1038 - val_acc: 0.2308\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.6137 - acc: 0.7566 - val_loss: 5.0507 - val_acc: 0.2692\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.5955 - acc: 0.7522 - val_loss: 5.1115 - val_acc: 0.2692\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.6559 - acc: 0.7478 - val_loss: 4.9753 - val_acc: 0.2308\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.6416 - acc: 0.7566 - val_loss: 4.8292 - val_acc: 0.2692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 1s - loss: 0.5909 - acc: 0.7655 - val_loss: 4.9425 - val_acc: 0.1923\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.6218 - acc: 0.7788 - val_loss: 5.0224 - val_acc: 0.1923\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.6314 - acc: 0.7566 - val_loss: 5.0488 - val_acc: 0.2308\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.5999 - acc: 0.7434 - val_loss: 5.0392 - val_acc: 0.1923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51251ff9e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batchsize批尺寸\n",
    "model.fit(a_train, b_train, epochs=100, batch_size=16, verbose=2, validation_data=(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_X, train_Y, batch_size=64, verbose=2, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(train_X)\n",
    "D=np.argmax(train_Y,axis = 1)\n",
    "E=np.argmax(trainPredict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=0 #total number of right\n",
    "for i,t in enumerate(E):\n",
    "    if D[i]==t :\n",
    "        A=A+1\n",
    "print(A/D.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
